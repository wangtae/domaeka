import random
import core.globals as g
from core.logger import logger
from core.utils.prefix_utils import parse_mention_analysis_request
from core.db_utils import get_user_hash_by_name, save_archived_message_to_db
from core.utils.cache_service import get_cached_response, cache_response
from core.utils.template_variables import process_template_variables_async
from core.sessions.session_manager import get_active_session
from services.llm_chat_sessions.session_processor import process_session_message
from services.llm_chat_sessions.session_commands import handle_session_command
from core.utils.command_parser import parse_full_input

# LLM ì„œë¹„ìŠ¤ ëª¨ë“ˆ import'
from services.openai_service import call_openai
from services.gemini_service import call_gemini
from services.deepseek_service import call_deepseek
from services.perplexity_service import call_perplexity
from services.grok_service import call_grok

# ê¸°íƒ€ ì„œë¹„ìŠ¤ ëª¨ë“ˆ import
from services.local_service import call_local_llm
from services.bible_service import bible_query
from services.recommend_lunch_service import recommend_lunch_menu
from services.lotto_service import generate_lotto_numbers
from services.profile_service import analyze_profile
from services.reload_all_json import reload_all_json_files
from services.chat_rank_service import get_chat_rank
from services.llm_fallback_service import call_llm_with_fallback
from services.weather_service import weather_service
from services.naver_weather_service import handle_weather_command
from services.proverb_service import get_random_investment_proverb, handle_today_proverb
from services.image_service import handle_image_command
from services.image_url_service import handle_image_url_command
from services.today_bible_service import handle_today_bible_command
from services.bloomberg_service import process_bloomberg_command
from services.exchange_rate_service import handle_exchange_rate_command
from services.conversation_summary_service import (
    handle_today_conversation_summary,
    handle_recent_conversation_summary,
    handle_user_conversation_summary
)
from services.youtube_service import handle_youtube_summary
from services.webpage_service import handle_webpage_summary
from services.profile_mbti_service import analyze_mbti
from services.profile_enneagram_service import analyze_enneagram
from services.tts_url_service import handle_tts_command, handle_tts_ko_command, handle_tts_en_command
from services.image_multi_service import handle_multiple_image_command
from services.ross_ai_service import handle_ross_ai_command
from services.imagen_service import handle_imagen_command
from services.config_generator_service import generate_bot_settings_from_db

# ì˜¤ëª© í•¸ë“¤ëŸ¬ import
from games.omok.handlers.start_game_handler import handle_start_command
from games.omok.handlers.join_game_handler import handle_join_game
from games.omok.handlers.stop_game_handler import handle_stop_command
from games.omok.handlers.omok_command_handler import handle_omok_command, handle_status_command

# ë™ì  ëª…ë ¹ì–´ ì‹œìŠ¤í…œ ì‚¬ìš©
from core.command_manager import command_manager

# ê¸°ì¡´ ì „ì—­ ë³€ìˆ˜ëŠ” fallbackìœ¼ë¡œ ë³´ì¡´
PREFIX_MAP = g.PREFIX_MAP
ENABLED_PREFIXES = g.ENABLED_PREFIXES


def is_bot_mention(target_name: str, bot_name: str):
    return target_name.strip().lower() == f"@{bot_name.lower()}"


async def handle_todo_list():
    todo_text = "ğŸ“‹ [í•  ì¼ ëª©ë¡]\n\n"
    todo_text += "\n".join([f"{idx + 1}. {item}" for idx, item in enumerate(g.TODO_ITEMS)])
    logger.info("[TODO_LIST] í•  ì¼ ëª©ë¡ ì¶œë ¥ ì™„ë£Œ")
    return todo_text


async def generate_tts_message(text_result, tts_config, bot_name=None, room_name=None):
    """
    ë©”ì‹œì§€ì— ëŒ€í•œ TTS ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” í•¨ìˆ˜
    TTS ë©”ì‹œì§€ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        if not tts_config or not tts_config.get("enabled", False):
            return None

        from services.tts_url_service import handle_tts_command

        # ê¸°ë³¸ê°’ ë³µì‚¬ + override ì ìš©
        config = g.TTS_DEFAULT_CONFIG.copy()
        custom_config = tts_config.get("config", {})
        if custom_config and isinstance(custom_config, dict):
            for key, value in custom_config.items():
                if key in config:
                    config[key] = value

        logger.info(f"[TTS] TTS ìƒì„± ì‹œì‘ â†’ {bot_name} / {room_name}")

        # TTS ìƒì„±
        tts_result = await handle_tts_command(text_result, config)

        # TTS ê²°ê³¼ ì²˜ë¦¬
        tts_message = None
        if isinstance(tts_result, list) and tts_result:
            tts_message = tts_result[0]
        elif isinstance(tts_result, str):
            tts_message = tts_result

        if not tts_message:
            logger.warning(f"[TTS] TTS ìƒì„± ê²°ê³¼ ì—†ìŒ â†’ {bot_name} / {room_name}")
            return None

        logger.info(f"[TTS] TTS ë©”ì‹œì§€ ìƒì„± ì„±ê³µ â†’ {bot_name} / {room_name}")
        return tts_message

    except Exception as e:
        logger.error(f"[TTS] TTS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ â†’ {e}", exc_info=True)
        return None


async def process_command(context: dict):
    prefix = context.get("prefix")

    original_prompt = context.get("prompt") or ""

    # ëª…ë ¹ì–´ ì •ì˜ ê°€ì ¸ì˜¤ê¸°
    command_info = PREFIX_MAP.get(prefix)
    command_type = command_info['type'] if command_info else None

    # íŒŒë¼ë¯¸í„°/í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬
    command_type, parameters, prompt = parse_full_input(
        input_text=context.get("prompt"),
        prefix_map=g.PREFIX_MAP,
        user_role=context.get("user_role", "user")
    )

    # íŒŒì‹±ëœ parametersë¥¼ contextì— ì €ì¥
    context["_prompt_parameters"] = parameters

    # [ì„¤ëª…]
    # parametersëŠ” ê¸°ì¡´ëŒ€ë¡œ ì„œë¹„ìŠ¤ í•¨ìˆ˜ì— ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
    # ê·¸ëŸ¬ë‚˜ ìƒˆë¡œìš´ ë°©ì‹ì—ì„œëŠ” ëª¨ë“  prompt íŒŒë¼ë¯¸í„°ê°€ context["_prompt_parameters"]ì— ì €ì¥ë˜ì–´
    # ì„œë¹„ìŠ¤ í•¨ìˆ˜ ë‚´ë¶€ ë˜ëŠ” LLM í˜¸ì¶œë¶€ ë“±ì—ì„œ context["_prompt_parameters"]ë¡œë„ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # (í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ë¥¼ ë³€ê²½í•˜ì§€ ì•Šê³ , context ê¸°ë°˜ì˜ ë²”ìš© íŒŒë¼ë¯¸í„° í™œìš©ì„ ì§€ì›)

    # --channel-id íŒŒë¼ë¯¸í„°ê°€ ìˆìœ¼ë©´ channel_id êµì²´ (ê´€ë¦¬ìë§Œ í—ˆìš©)
    if parameters and "channel-id" in parameters:
        from core.utils.auth_utils import is_admin
        context["_original_channel_id"] = context.get("channel_id")
        if not is_admin(context["_original_channel_id"], context.get("user_hash")):
            logger.warning(f"[ADMIN_ONLY] --channel-idëŠ” ê´€ë¦¬ìë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (user_hash={context.get('user_hash')}, _original_channel_id={context['_original_channel_id']}, requested_channel_id={parameters['channel-id']})")
            return "@no-reply"
        context["channel_id"] = parameters["channel-id"]

    # ë””ë²„ê¹…
    logger.debug(f"[PARSED_PARAMETERS] {parameters}")
    logger.debug(f"[PARSED_PROMPT] {prompt}")

    bot_name = context.get("bot_name")
    channel_id = context.get("channel_id")
    user_hash = context.get("user_hash")
    room_name = context.get("room")
    sender = context.get("sender")
    client_key = context.get('client_key')
    # ìŠ¤ì¼€ì¤„ë§ëœ ë©”ì‹œì§€ì¸ì§€ ì—¬ë¶€ í™•ì¸ (scheduler.pyì—ì„œ ì„¤ì •)
    is_scheduled = context.get('is_scheduled', False)

    room_data = g.schedule_rooms.get(bot_name, {}).get(channel_id, {})
    bot_nickname = room_data.get("bot_nickname", bot_name)

    logger.debug(f"[PROCESS_COMMAND] prefix={prefix}, prompt={prompt}, is_scheduled={is_scheduled}")

    if prefix == ">" and prompt.startswith("@"):
        target_name, target_channel_id, analysis_type = parse_mention_analysis_request(prompt)
        if target_name and analysis_type:
            logger.debug(f"[MENTION_ANALYZE] ìë™ ë¶„ì„ ìš”ì²­ ê°ì§€ë¨ â†’ {target_name}, type: {analysis_type}")
            target_channel_id = target_channel_id or channel_id
            target_user_hash = await get_user_hash_by_name(g.db_pool, target_channel_id, target_name)

            if not target_user_hash:
                return f"âŒ í•´ë‹¹ ë°©ì—ì„œ '{target_name}' ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”."

            if analysis_type == "profile":
                return await analyze_profile(
                    bot_name=bot_name,
                    channel_id=target_channel_id,
                    user_hash=target_user_hash,
                    prompt=prompt,
                    parameters=parameters,
                    sender=sender,
                    is_self=False
                )
            elif analysis_type == "mbti":
                return await analyze_mbti(
                    bot_name=bot_name,
                    channel_id=target_channel_id,
                    user_hash=target_user_hash,
                    sender=sender,
                    room_name=room_name
                )
            elif analysis_type == "enneagram":
                return await analyze_enneagram(
                    bot_name=bot_name,
                    channel_id=target_channel_id,
                    user_hash=target_user_hash,
                    sender=sender,
                    room_name=room_name
                )

    # prefixê°€ Noneì¸ ê²½ìš° ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
    if prefix is None:
        if not context.get("disable_command_logs", False):
            logger.debug(f"[NO_PREFIX] prefixê°€ ì—†ëŠ” ë©”ì‹œì§€ â†’ ëª…ë ¹ì–´ ì²˜ë¦¬ ê±´ë„ˆëœ€")
        return None

    # ë™ì  ëª…ë ¹ì–´ ì‹œìŠ¤í…œ ì‚¬ìš©: ë´‡ë³„/ë°©ë³„ ëª…ë ¹ì–´ í™•ì¸
    bot_enabled_prefixes = command_manager.get_bot_enabled_prefixes(bot_name, channel_id)
    if bot_enabled_prefixes and prefix not in bot_enabled_prefixes:
        # ë´‡ë³„ ëª…ë ¹ì–´ê°€ ë¡œë“œë˜ì–´ ìˆê³ , í•´ë‹¹ ì ‘ë‘ì–´ê°€ ë¹„í™œì„±í™”ëœ ê²½ìš°
        if not context.get("disable_command_logs", False):
            logger.warning(f"[DISABLED] ë´‡ '{bot_name}'ì—ì„œ ë¹„í™œì„±í™”ëœ ëª…ë ¹ì–´ì…ë‹ˆë‹¤. (prefix: {prefix})")
            return None
    elif not bot_enabled_prefixes and prefix not in ENABLED_PREFIXES:
        # ë´‡ë³„ ëª…ë ¹ì–´ê°€ ì—†ê³ , ê¸€ë¡œë²Œ ëª…ë ¹ì–´ì—ì„œë„ ë¹„í™œì„±í™”ëœ ê²½ìš°
        if not context.get("disable_command_logs", False):
            logger.warning(f"[DISABLED] ë¹„í™œì„±í™”ëœ ëª…ë ¹ì–´ì…ë‹ˆë‹¤. (prefix: {prefix})")
            return None

    # ë™ì  ëª…ë ¹ì–´ ì‹œìŠ¤í…œì—ì„œ ëª…ë ¹ì–´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    command_info = command_manager.get_bot_command_info(bot_name, channel_id, prefix)
    if not command_info:
        # ë´‡ë³„ ëª…ë ¹ì–´ì— ì—†ìœ¼ë©´ ê¸€ë¡œë²Œ fallback ì‚¬ìš©
        command_info = PREFIX_MAP.get(prefix)
        logger.error(f"[ERROR] ë´‡ë³„ ëª…ë ¹ì–´ì— ì—†ì–´ ê¸€ë¡œë²Œ fallback ì‚¬ìš©í•©ë‹ˆë‹¤. (ìˆì–´ì„œëŠ” ì•ˆë˜ëŠ” ìƒí™©ì´ì§€ë§Œ ê²€ì¦ ì „ê¹Œì§„ í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ë‚¨ê²¨ë‘ )")
        if not command_info:
            if not context.get("disable_command_logs", False):
                logger.warning(f"[UNKNOWN PREFIX] ì§€ì›ë˜ì§€ ì•ŠëŠ” ì ‘ë‘ì–´ì…ë‹ˆë‹¤. ({prefix})")
                return "[ERROR] ì§€ì›ë˜ì§€ ì•ŠëŠ” ì ‘ë‘ì–´ì…ë‹ˆë‹¤."

    command_type = command_info['type']
    if not context.get("disable_command_logs", False):
        logger.debug(f"[COMMAND_TYPE] {command_type}")
        logger.debug(f"g.json_command_dataì—ì„œ í•´ë‹¹ ëª…ë ¹ì–´ ì„¤ì •: {g.json_command_data.get(command_type, {})}")

    # ìºì‹œ í™•ì¸ ë£¨í‹´ì€ ì™¸ë¶€ë¡œ ì´ë™ (message_processor.pyì—ì„œ ì²˜ë¦¬)
    # ëŒ€ì‹  ìºì‹œ í™•ì¸ í”Œë˜ê·¸ ì„¤ì •
    if context.get('skip_cache_check', False):
        # message_processor.pyì—ì„œ ì´ë¯¸ ìºì‹œ í™•ì¸ì„ í–ˆìœ¼ë¯€ë¡œ ê±´ë„ˆëœ€
        logger.debug("[CACHE_CHECK] ìºì‹œ í™•ì¸ ê±´ë„ˆëœ€ (message_processor.pyì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨)")
    else:
        # ê³¼ê±° ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ë‚¨ê²¨ë‘  (ì™¸ë¶€ì—ì„œ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ê²½ìš°)
        cached_response = await get_cached_response(command_type, prompt)
        if cached_response:
            logger.info(f"[CACHE_HIT] {command_type} - {prompt[:30]}...")
            return cached_response

    try:
        result = None

        LLM_system_prompt = g.LLM_DEFAULT_SYSTEM_PROMPT

        if command_type == 'help':
            result = g.generate_help_message(bot_name=bot_name, channel_id=channel_id)

        elif command_type == 'reload_env':
            # generate_bot_settings_from_db í•¨ìˆ˜ê°€ successì™€ ë©”ì‹œì§€ë¥¼ íŠœí”Œë¡œ ë°˜í™˜
            success, message = await generate_bot_settings_from_db()
            if success:
                result = f"âœ… ë´‡ ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ: {message}"
            else:
                result = f"âŒ ë´‡ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {message}"

        elif command_type == 'reload_bot_settings':
            # íŠ¹ì • ë´‡ì˜ ì„¤ì •ë§Œ ì¬ìƒì„± (í”„ë¡¬í”„íŠ¸ì—ì„œ ë´‡ ì´ë¦„ ì¶”ì¶œ)
            if prompt and prompt.strip():
                target_bot_name = prompt.strip()
                success, message = await generate_bot_settings_from_db(target_bot_name)
                if success:
                    result = f"âœ… '{target_bot_name}' ë´‡ ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ: {message}"
                else:
                    result = f"âŒ '{target_bot_name}' ë´‡ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {message}"
            else:
                # í”„ë¡¬í”„íŠ¸ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ë´‡ì˜ ì„¤ì • ì¬ìƒì„±
                success, message = await generate_bot_settings_from_db(bot_name)
                if success:
                    result = f"âœ… '{bot_name}' ë´‡ ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ: {message}"
                else:
                    result = f"âŒ '{bot_name}' ë´‡ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {message}"

        elif command_type == 'profile_analyze':
            target_name, target_channel_id, _ = parse_mention_analysis_request(prompt or "")
            if target_name:
                target_channel_id = target_channel_id or channel_id
                target_user_hash = await get_user_hash_by_name(g.db_pool, target_channel_id, target_name)

                if not target_user_hash:
                    result = f"âŒ í•´ë‹¹ ë°©ì—ì„œ '{target_name}' ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”."
                else:
                    result = await analyze_profile(
                        bot_name=bot_name,
                        channel_id=target_channel_id,
                        user_hash=target_user_hash,
                        prompt=prompt,
                        parameters=parameters,
                        sender=target_name,
                        is_self=False
                    )
            else:
                if not user_hash:
                    logger.warning("[PROFILE_ANALYZE] user_hashê°€ ëˆ„ë½ë¨ â†’ ìš”ì²­ ë¶ˆê°€")
                    result = random.choice(g.LLM_ERROR_MESSAGES)
                else:
                    result = await analyze_profile(
                        bot_name=bot_name,
                        channel_id=channel_id,
                        user_hash=user_hash,
                        prompt=prompt,
                        parameters=parameters,
                        sender=sender,
                        is_self=True
                    )

        elif command_type == 'mbti_analyze':
            if not user_hash:
                logger.warning("[MBTI_ANALYZE] user_hashê°€ ëˆ„ë½ë¨ â†’ ìš”ì²­ ë¶ˆê°€")
                result = random.choice(g.LLM_ERROR_MESSAGES)
            else:
                result = await analyze_mbti(
                    bot_name=bot_name,
                    channel_id=channel_id,
                    user_hash=user_hash,
                    sender=sender,
                    room_name=room_name
                )

        elif command_type == 'enneagram_analyze':
            if not user_hash:
                logger.warning("[ENNEAGRAM_ANALYZE] user_hashê°€ ëˆ„ë½ë¨ â†’ ìš”ì²­ ë¶ˆê°€")
                result = random.choice(g.LLM_ERROR_MESSAGES)
            else:
                result = await analyze_enneagram(
                    bot_name=bot_name,
                    channel_id=channel_id,
                    user_hash=user_hash,
                    sender=sender,
                    room_name=room_name
                )

        elif command_type == 'reload-all-json':
            logger.debug("[COMMAND] ğŸ” JSON ë¦¬ë¡œë“œ ëª…ë ¹ ì‹¤í–‰ë¨")
            detail_msg = await reload_all_json_files()
            logger.debug(f"[COMMAND] ğŸ” ë¦¬ë¡œë“œ ê²°ê³¼ detail_msg=\n{detail_msg}")
            result = detail_msg

        # LLM_DEFAULT_SYSTEM_PROMPT ë³€ìˆ˜ë¥¼ globals.pyì—ì„œ ê°€ì ¸ì˜¤ê¸°
        elif command_type == 'mention':
            if not prompt.startswith("@"):
                result = "[ERROR] @ëŒ€ìƒì´ í•„ìš”í•©ë‹ˆë‹¤. ì˜ˆ: [ë‚˜ë¥¼ ë©˜ì…˜] @LOA.i ì§ˆë¬¸"
            else:
                # âœ… ì‚¬ìš©ì ë¶„ì„ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ íŒë‹¨
                target_name, target_channel_id, analysis_type = parse_mention_analysis_request(prompt)
                if target_name and analysis_type:
                    # ì±„ë„ IDê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì±„ë„ ID ì‚¬ìš©
                    target_channel_id = target_channel_id or channel_id
                    target_user_hash = await get_user_hash_by_name(g.db_pool, target_channel_id, target_name)

                    if not target_user_hash:
                        result = f"âŒ í•´ë‹¹ ë°©ì—ì„œ '{target_name}' ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”."
                    else:
                        if analysis_type == "profile":
                            result = await analyze_profile(
                                bot_name=bot_name,
                                channel_id=target_channel_id,
                                user_hash=target_user_hash,
                                prompt=prompt,
                                parameters=parameters,
                                sender=target_name,
                                is_self=False
                            )
                        elif analysis_type == "mbti":
                            result = await analyze_mbti(
                                bot_name=bot_name,
                                channel_id=target_channel_id,
                                user_hash=target_user_hash,
                                sender=target_name,
                                room_name=room_name
                            )
                        elif analysis_type == "enneagram":
                            result = await analyze_enneagram(
                                bot_name=bot_name,
                                channel_id=target_channel_id,
                                user_hash=target_user_hash,
                                sender=target_name,
                                room_name=room_name
                            )
                else:
                    # ê¸°ì¡´ @ë´‡ í˜¸ì¶œ ì²˜ë¦¬
                    target, *rest = prompt.split(maxsplit=1)
                    question = rest[0] if rest else ""

                    if is_bot_mention(target, bot_name):
                        if not question or question.strip() == "":
                            result = "@no-reply"
                        else:
                            system_prompt = g.LLM_DEFAULT_SYSTEM_PROMPT
                            providers = [
                                {"name": "grok", "model": "grok-3-latest", "timeout": 30, "retry": 0, "system_prompt": system_prompt},
                                {"name": "gemini", "model": "gemini-1.5-pro", "timeout": 30, "retry": 0, "system_prompt": system_prompt},
                                {"name": "openai", "model": "gpt-4o", "timeout": 30, "retry": 0, "system_prompt": system_prompt},
                                {"name": "gemini-flash", "model": "gemini-1.5-flash", "timeout": 30, "retry": 0, "system_prompt": system_prompt},
                                {"name": "deepseek", "model": "deepseek-chat", "timeout": 30, "retry": 0, "system_prompt": system_prompt}
                            ]
                            received_message_context = {
                                "bot_name": bot_name,
                                "channel_id": channel_id,
                                "user_hash": user_hash,
                                "sender": sender,
                                "room": context.get("room")
                            }
                            result = await call_llm_with_fallback(received_message_context, question, providers)
                    else:
                        result = f"ğŸ§‘â€ğŸ« @{target[1:]} ë‹˜ì„ ëŒ€ìƒìœ¼ë¡œ í•œ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ëŠ” ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤."

        elif command_type == 'echo':
            result = prompt if prompt else None

        elif command_type == 'openai':
            # ìƒˆë¡œìš´ API ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ
            model = "gpt-4o"  # ë˜ëŠ” "gpt-3.5-turbo", "gpt-4", ë“±
            LLM_system_prompt += "5. ì„¤ëª…ì´ ì˜ë¦¬ì§€ ì•Šê²Œ ê°€ëŠ¥í•œ í•œ 30ì´ˆ ì´ë‚´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
            data = {
                "messages": [
                    {"role": "system", "content": LLM_system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 1500
            }

            result = await call_openai(model, data)

        elif command_type == 'grok':
            # ìƒˆë¡œìš´ API ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ
            model = "grok-3-latest"
            LLM_system_prompt += "5. ì„¤ëª…ì´ ì˜ë¦¬ì§€ ì•Šê²Œ ê°€ëŠ¥í•œ í•œ 30ì´ˆ ì´ë‚´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
            data = {
                "messages": [
                    {"role": "system", "content": LLM_system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 1500
            }

            result = await call_grok(model, data)

        elif command_type == 'gemini':
            # ìƒˆë¡œìš´ API ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ
            model = "gemini-1.5-pro"
            LLM_system_prompt += "5. ì„¤ëª…ì´ ì˜ë¦¬ì§€ ì•Šê²Œ ê°€ëŠ¥í•œ í•œ 30ì´ˆ ì´ë‚´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
            data = {
                "messages": [
                    {"role": "system", "content": LLM_system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 1500
            }
            result = await call_gemini(model, data)

        elif command_type == 'deepseek':
            # ìƒˆë¡œìš´ API ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ
            model = "deepseek-chat"
            LLM_system_prompt += "5. ì„¤ëª…ì´ ì˜ë¦¬ì§€ ì•Šê²Œ ê°€ëŠ¥í•œ í•œ 30ì´ˆ ì´ë‚´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
            data = {
                "messages": [
                    {"role": "system", "content": LLM_system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 1500
            }
            result = await call_deepseek(model, data)

        elif command_type == 'perplexity':
            # ìƒˆë¡œìš´ API ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ
            model = "sonar-pro"
            LLM_system_prompt += "5. ì„¤ëª…ì´ ì˜ë¦¬ì§€ ì•Šê²Œ ê°€ëŠ¥í•œ í•œ 30ì´ˆ ì´ë‚´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
            data = {
                "messages": [
                    {"role": "system", "content": LLM_system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 1500
            }
            result = await call_perplexity(model, data)

        elif command_type == 'llm_fallback':
            # llm_fallback_serviceëŠ” ê¸°ì¡´ ë°©ì‹ ìœ ì§€ (ë‚´ë¶€ì—ì„œ ìƒˆ API ì‚¬ìš©)
            result = await call_llm_with_fallback(context, prompt)

        elif command_type == 'local_llm':
            result = await call_local_llm(prompt)

        elif command_type == "bot_auto_reply":
            # ìµœê·¼ ëŒ€í™” ì¡°íšŒ
            from core.db_utils import fetch_recent_messages
            history = await fetch_recent_messages(g.db_pool, channel_id, None, limit=100, minutes=30)
            history = [{"role": "user", "content": msg} for msg in reversed(history)]
            history.append({"role": "user", "content": prompt})

            system_prompt = f"ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì‚¬ë‘ìŠ¤ëŸ¬ìš´ ì‚¬ëŒì´ë©° ì´ë¦„ì€ '{bot_nickname}'ì…ë‹ˆë‹¤. ë‹µë³€ì„ ì¤„ ë•Œ ë‹¤ìŒ ê·œì¹™ì„ ì§€ì¼œì£¼ì„¸ìš”: 1. ê³µì†í•˜ê³  ì¹œì ˆí•œ ë§íˆ¬ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”. 2. ëŒ€í™” ì°¸ì—¬ìì¸ê²ƒ ì²˜ëŸ¼ ì‘ë‹µí•´ ì£¼ì„¸ìš”. 3. ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ì—ëŠ” ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , í™•ì‹¤í•˜ì§€ ì•Šì€ ê²½ìš°ì—ëŠ” ì†”ì§í•˜ê²Œ ì•Œë ¤ì£¼ì„¸ìš”."

            providers = [
                {"name": "grok", "model": "grok-3-latest", "timeout": 30, "retry": 0, "system_prompt": system_prompt},
                {"name": "gemini", "model": "gemini-1.5-pro", "timeout": 30, "retry": 0, "system_prompt": system_prompt},
                {"name": "openai", "model": "gpt-4o", "timeout": 30, "retry": 0, "system_prompt": system_prompt},
                {"name": "gemini-flash", "model": "gemini-1.5-flash", "timeout": 30, "retry": 0, "system_prompt": system_prompt},
                {"name": "deepseek", "model": "deepseek-chat", "timeout": 30, "retry": 0, "system_prompt": system_prompt}
            ]

            user_prompt = f"""
            ë‹¤ìŒì€ ìµœê·¼ ëŒ€í™”ë°©ì˜ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤:
            
            {history}
            
            ê°€ì¥ ë§ˆì§€ë§‰ ëŒ€í™”ê°€ ì‘ë‹µí•´ì•¼í•  ë©”ì‹œì§€ì´ë©° ë‚˜ë¨¸ì§€ ëŒ€í™”ë“¤ì€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ê°€ ì‘ì„±ë˜ê¸° ìœ„í•œ ì°¸ê³ ìš© ë©”ì‹œì§€ë“¤ì…ë‹ˆë‹¤.
            
            ì´ ëŒ€í™”ì— ìì—°ìŠ¤ëŸ½ê²Œ ì°¸ì—¬í•  ìˆ˜ ìˆëŠ” 1-3ë¬¸ì¥ ì •ë„ì˜ ì§§ì€ ì‘ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”. 
            ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ í•„ìš”í•œ ë§Œí¼ ìƒì„¸íˆ í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.
            ë‹¹ì‹ ë„ ëŒ€í™” ì°¸ì—¬ìì¸ ê²ƒì²˜ëŸ¼ ë³´ì—¬ì§€ë©´ ì¢‹ì•„ìš”.
            """

            result = await call_llm_with_fallback(
                {
                    "bot_name": bot_name,
                    "channel_id": channel_id,
                    "room": room_name,
                    "user_hash": user_hash,
                    "sender": sender
                },
                user_prompt,
                providers=providers
            )

        elif command_type in ['bible', 'bible_random']:
            result = await bible_query(command_type, prompt, channel_id=channel_id, user_hash=user_hash)

        elif command_type in ['bible_search_all', 'bible_search_old', 'bible_search_new']:
            result = await bible_query(command_type, prompt, channel_id=channel_id, user_hash=user_hash)

        elif command_type == 'lotto':
            result = await generate_lotto_numbers()

        elif command_type == 'weather':
            result = await weather_service()
            logger.debug(f"[WEATHER_RESULT] {result}")

        elif command_type == 'naver_weather':
            result = await handle_weather_command(prompt)

        elif command_type == 'recomment_lunch_menu':
            result = await recommend_lunch_menu()

        elif command_type == 'today_proverb':
            result = await handle_today_proverb(prompt)

        elif command_type == "chat_rank_week":
            result = await get_chat_rank(channel_id, room_name, only_meaningful=True, days=7)

        elif command_type == "chat_rank_week_all":
            result = await get_chat_rank(channel_id, room_name, only_meaningful=False, days=7)

        elif command_type == "chat_rank":
            result = await get_chat_rank(channel_id, room_name, only_meaningful=True)

        elif command_type == "chat_rank_all":
            result = await get_chat_rank(channel_id, room_name, only_meaningful=False)

        elif command_type == 'image_generator':
            result = await handle_image_command(prompt)

        elif command_type == 'image_url_generator':
            result = await handle_image_url_command(prompt)

        elif command_type == 'today_bible':
            # ë§¤ì¼ì„±ê²½ ë¬µìƒ ëª…ë ¹ì–´ ì¶”ê°€
            result = await handle_today_bible_command()

        elif command_type == 'today_bible2':
            # ë§¤ì¼ì„±ê²½ ë¬µìƒ ëª…ë ¹ì–´ ì¶”ê°€

            template_context = {
                "channel_id": context.get("channel_id"),
                "username": context.get("sender"),
                "room": context.get("room"),
                "date_hash_modulo": 66
            }

            prompt_for_llm = await process_template_variables_async("""\
> ì˜¤ëŠ˜ì˜ ì„±ê²½ êµ¬ì ˆê³¼ ë¬µìƒ ê¸€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.

- ë‹¤ìŒì€ ì„ íƒí•  ì„±ê²½ì˜ ì¥ì˜ ë‚´ìš©ì…ë‹ˆë‹¤.

{{RANDOM_BIBLE_CHAPTER_CONTENT}}

- ì´ ì„ íƒëœ ì¥ì—ì„œ ì„±ê²½ ë¬µìƒê¸€ì„ ì‘ì„±í•  ëŒ€ìƒì´ ë˜ëŠ” êµ¬ì ˆì„ ì„ íƒí•´ ì£¼ì„¸ìš”.
- ë¬µìƒ ê¸€ì€ ê¹Šì´ ìˆëŠ” ë¬µìƒ ê¸€ë¡œ ğŸ“– ì˜¤ë¥¸ìª½ì— ë°”ë¡œ ì´ì–´ì„œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
- ì•„ë˜ [í˜•ì‹]ì„ ë°˜ë“œì‹œ ì§€ì¼œ ì£¼ì„¸ìš”. ë‚´ìš© ì•ˆì˜ (êµ¿)ì€ ì¹´ì¹´ì˜¤í†¡ ì´ëª¨í‹°ì½˜ì´ë¯€ë¡œ ì¶œë ¥í•  ë•Œ í¬í•¨í•˜ì„¸ìš”.
- ì „ì²´ ë‚´ìš©ì„ í•œê¸€ 500ì ë¯¸ë§Œìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

[í˜•ì‹]

(êµ¿) ì˜¤ëŠ˜ì˜ ì„±ê²½ ë§ì”€!

êµ¬ì ˆ ë‚´ìš© (ì„±ê²½ ì•½ì‹ ì´ë¦„ + ì¥ + ì ˆ)

ğŸ“–""", template_context)
            result = await call_llm_with_fallback(context, prompt_for_llm)

        elif command_type == 'bloomberg_news':
            result = await process_bloomberg_command(context)

        elif command_type == 'exchange_rate':
            result = await handle_exchange_rate_command(prompt)

        # process_command í•¨ìˆ˜ ë‚´ì— ë‹¤ìŒ ì½”ë“œ ì¶”ê°€
        elif command_type == 'today_conversation_summary':
            result = await handle_today_conversation_summary(prompt, parameters, context) # parametersëŠ” ì•ìœ¼ë¡œ ì‚¬ìš© ì•ˆí•¨

        elif command_type == 'today_conversation_summary_meaningful':
            context['prefix'] = context.get('prefix', '') + '!'  # '!'ê°€ ìˆìœ¼ë©´ ì˜ë¯¸ ìˆëŠ” ë©”ì‹œì§€ë§Œ í¬í•¨
            result = await handle_today_conversation_summary(prompt, parameters, context) # parametersëŠ” ì•ìœ¼ë¡œ ì‚¬ìš© ì•ˆí•¨

        elif command_type == 'recent_conversation_summary':
            result = await handle_recent_conversation_summary(prompt, parameters, context) # parametersëŠ” ì•ìœ¼ë¡œ ì‚¬ìš© ì•ˆí•¨

        elif command_type == 'recent_conversation_summary_meaningful':
            context['prefix'] = context.get('prefix', '') + '!'  # '!'ê°€ ìˆìœ¼ë©´ ì˜ë¯¸ ìˆëŠ” ë©”ì‹œì§€ë§Œ í¬í•¨
            result = await handle_recent_conversation_summary(prompt, parameters, context) # parametersëŠ” ì•ìœ¼ë¡œ ì‚¬ìš© ì•ˆí•¨

        elif command_type == 'user_conversation_summary':
            result = await handle_user_conversation_summary(prompt, parameters, context)

        elif command_type == 'user_conversation_summary_meaningful':
            context['prefix'] = context.get('prefix', '') + '!'  # '!'ê°€ ìˆìœ¼ë©´ ì˜ë¯¸ ìˆëŠ” ë©”ì‹œì§€ë§Œ í¬í•¨
            result = await handle_user_conversation_summary(prompt, parameters, context)

        # ë‹¤ë¥¸ elif êµ¬ë¬¸ë“¤ ì‚¬ì´ì— ì¶”ê°€
        elif command_type in ['start_private_chat', 'start_group_chat', 'extend_chat', 'end_chat']:
            # ì„¸ì…˜ ëª…ë ¹ì–´ ì²˜ë¦¬
            await handle_session_command(context, command_type)
            return None

        elif command_type == 'youtube_summary':
            logger.debug(f"[DEBUG_CONTEXT_YOUTUBE] context before youtube_summary: {context}")
            result = await handle_youtube_summary(prompt, context)

        elif command_type == 'webpage_summary':
            logger.debug(f"[DEBUG_CONTEXT_WEBPAGE] context before webpage_summary: {context}")
            result = await handle_webpage_summary(prompt, context)

        elif command_type == "korea_market_briefing":
            from services.LS_t1514_service import fetch_briefing
            return await fetch_briefing()

        elif command_type == "version_history":
            from services.version_service import get_version_history_message
            return get_version_history_message()

        elif command_type == "block_conversation_join":
            from core.message_processor import handle_conversation_block_command
            return await handle_conversation_block_command(context)

        elif command_type == 'tts':
            # ê¸°ë³¸ TTS ëª…ë ¹ì–´ (ì–¸ì–´ ìë™ ê°ì§€)
            tts_config = {
                "language": "auto",
                "gender": "F",
                "voice": "auto",
                "intro": [
                    "ğŸ§ ìŒì„±ìœ¼ë¡œ ë…¹ìŒí•´ ë³´ì•˜ì–´ìš”!",
                    "ğŸ”” ë‚´ìš©ì„ ë…¹ìŒí•´ ë³´ì•˜ì–´ìš”.",
                    "ğŸ™ï¸ ì§ì ‘ ì½ì–´ë´¤ì–´ìš”!",
                    "ğŸ§ ì´ ë‚´ìš©ì„ ë“¤ë ¤ë“œë¦´ê²Œìš”.",
                    "ğŸ“‹ ìŒì„±ìœ¼ë¡œ ì •ë¦¬í•´ ë“œë¦´ê²Œìš”!",
                    "ğŸ¤ ì œê°€ ì½ì–´ë³¼ê²Œìš”~",
                    "ğŸ™ ì§§ê²Œ ë…¹ìŒí•´ë´¤ì–´ìš”!ï¸",
                    "ğŸ‘‚ ë“¤ì–´ë³´ëŠ” ê²Œ ë” í¸í•˜ì£ ?",
                    "ğŸ—£ï¸ ë§ë¡œ ì „í•´ë“œë¦´ê²Œìš”!"
                ]
            }
            return await handle_tts_command(prompt, tts_config)

        elif command_type == 'tts_ko':
            # í•œêµ­ì–´ TTS ëª…ë ¹ì–´
            tts_config = {
                "language": "ko-KR",
                "gender": "F",
                "voice": "auto"
            }
            return await handle_tts_ko_command(prompt)

        elif command_type == 'tts_en':
            # ì˜ì–´ TTS ëª…ë ¹ì–´
            tts_config = {
                "language": "en-US",
                "gender": "F",
                "voice": "auto"
            }
            return await handle_tts_en_command(prompt)

        # ì•„ë˜ì²˜ëŸ¼ command_type ë¶„ê¸°ì— ì¶”ê°€
        elif command_type == "omok_start":
            return await handle_start_command(prompt, parameters, context) # parametersëŠ” ì•ìœ¼ë¡œ ì‚¬ìš© ì•ˆí•¨

        elif command_type == "omok_join":
            return await handle_join_game(prompt, context)

        elif command_type == "omok_stop":
            return await handle_stop_command(prompt, context)

        elif command_type == 'todo_list':
            result = await handle_todo_list()

        elif command_type == 'multi_image_generator':
            result = await handle_multiple_image_command(prompt)

        elif command_type == 'show_llm_models':
            from services.show_llm_models import show_llm_models
            result = await show_llm_models(context)

        elif command_type == 'ross_ai':
            result = await handle_ross_ai_command(context, prompt)

        elif command_type == 'imagen_generate':
            result = await handle_imagen_command(context, prompt)

        else:
            logger.error(f"[UNKNOWN_COMMAND_TYPE] {command_type}")
            result = "[ERROR] ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì…ë‹ˆë‹¤."

        # ê²°ê³¼ ë°˜í™˜ ì „ ì²˜ë¦¬
        if result is not None:
            # ìŠ¤ì¼€ì¤„ë§ëœ ë©”ì‹œì§€ì´ê³  TTS ì„¤ì •ì´ ìˆëŠ” ê²½ìš° TTS ì¶”ê°€
            tts_config = context.get("tts_config")
            if tts_config and tts_config.get("enabled", False) and context.get("is_scheduled", False):
                # í…ìŠ¤íŠ¸ ê²°ê³¼ ì¶”ì¶œ
                text_result = result[0] if isinstance(result, list) and result else result

                # TTS ìƒì„±
                tts_message = await generate_tts_message(
                    text_result,
                    tts_config,
                    context.get("bot_name"),
                    context.get("room")
                )

                # TTS ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì›ë³¸ ê²°ê³¼ì— ì¶”ê°€
                if tts_message:
                    if isinstance(result, list):
                        result.append(tts_message)
                    else:
                        result = [result, tts_message]

            # âœ… ìºì‹œ ì €ì¥ ë¡œì§ ì¶”ê°€
            # cache_responseëŠ” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ, resultë¥¼ í•­ìƒ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            messages_to_cache = result if isinstance(result, list) else [result]
            
            # cache_response ë‚´ë¶€ì—ì„œ cache_enabled ì—¬ë¶€ë¥¼ í™•ì¸í•˜ë¯€ë¡œ ë³„ë„ ì²´í¬ í•„ìš” ì—†ìŒ
            await cache_response(command_type, prompt, messages_to_cache)
            logger.info(f"[CACHE_SAVE] ìºì‹œ ì €ì¥ ìš”ì²­: {command_type} - {prompt[:30]}...")

            # ê²°ê³¼ê°€ stringì´ ì•„ë‹ˆê±°ë‚˜ @no-replyì¸ ê²½ìš° ì•„ì¹´ì´ë¸Œí•˜ì§€ ì•ŠìŒ
            if command_info and command_info.get("enable-archiving", False) and result and result != "@no-reply":
                try:
                    # contextì— command_nameê³¼ command_type ì¶”ê°€
                    context["command_name"] = prefix
                    context["command_type"] = command_type
                    await save_archived_message_to_db(g.db_pool, context, result)
                except Exception as e:
                    logger.error(f"[ARCHIVE_SAVE_ERROR] ëª…ë ¹ì–´ ê²°ê³¼ ì•„ì¹´ì´ë¸Œ ì €ì¥ ì‹¤íŒ¨ (command: {prefix}) â†’ {e}", exc_info=True)

            return result # ìµœì¢… ê²°ê³¼ ë°˜í™˜ (str ë˜ëŠ” List[str])
        
        # resultê°€ Noneì¸ ê²½ìš° (ì˜ˆ: @no-reply ë˜ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ None ë°˜í™˜)
        return result 

    except Exception as e:
        logger.exception(f"[PROCESS_COMMAND_ERROR] {e}")
        # ìŠ¤ì¼€ì¤„ë§ëœ ë©”ì‹œì§€ì˜ ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŒ
        if is_scheduled: # is_scheduled ë³€ìˆ˜ëŠ” í•¨ìˆ˜ ìƒë‹¨ì—ì„œ ì´ë¯¸ contextì—ì„œ ê°€ì ¸ì˜´
            logger.error(f"[SCHEDULED_COMMAND_ERROR] ìŠ¤ì¼€ì¤„ ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return None  # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜í•˜ì—¬ ë©”ì‹œì§€ ì „ì†¡ ì•ˆí•¨
        return "[ERROR] ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨"
