# âœ… services/profile_service.py
import json
import core.globals as g
from core.logger import logger
from services.llm_fallback_service import call_llm_with_fallback
from core.db_utils import fetch_recent_messages
from core.globals import find_provider_by_model

# âœ… í”„ë¡œí•„ ë¶„ì„ ì„¤ì • ë¡œë“œ
try:
    with g.JSON_CONFIG_FILES["profile_analysis"].open(encoding="utf-8") as f:
        profile_config = json.load(f)
        logger.info("[CONFIG] í”„ë¡œí•„ ë¶„ì„ ì„¤ì • ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    profile_config = {}
    logger.exception(f"[ERROR] profile_analysis.json ë¡œë“œ ì‹¤íŒ¨ â†’ {e}")


# âœ… ë£¸ë³„ ì„¤ì •ê°’ ì¡°íšŒ
def get_room_config(bot_name, channel_id):
    defaults = profile_config.get("defaults", {})
    return profile_config.get("rooms", {}).get(bot_name, {}).get(str(channel_id), {}) or defaults


# âœ… ê¸°ë³¸ providers ìƒì„±
def get_default_providers(system_prompt):
    return [
        {
            "name": "openai",
            "timeout": 30,
            "model": "gpt-4o",
            "retry": 0,
            "system_prompt": system_prompt
        },
        {
            "name": "gemini",
            "model": "gemini-1.5-pro",
            "timeout": 30,
            "retry": 0,
            "system_prompt": system_prompt
        },
        {
            "name": "grok",
            "model": "grok-3-latest",
            "timeout": 30,
            "retry": 0,
            "system_prompt": system_prompt
        }
    ]


# âœ… í”„ë¡œí•„ ë¶„ì„ í•¨ìˆ˜
async def analyze_profile(bot_name, channel_id, user_hash, prompt, parameters=None, is_self=True, room_name=None,
                          sender=None):
    parameters = parameters or {}  # None ë°©ì§€

    # ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    room_config = get_room_config(bot_name, channel_id)
    defaults = profile_config.get("defaults", {})

    # íˆìŠ¤í† ë¦¬ ì„¤ì •
    history_limit = room_config.get("history_limit", defaults.get("history_limit", 500))
    min_required = room_config.get("self_min_history" if is_self else "other_min_history", 10)

    logger.debug(f"[PROFILE_ANALYSIS] íˆìŠ¤í† ë¦¬: {history_limit}, ìµœì†Œ í•„ìš”: {min_required}")
    logger.debug(f"[USER_HASH] {user_hash}, [ROOM_NAME] {channel_id}, [SENDER] {sender}")

    # ëŒ€í™” ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°
    history = await fetch_recent_messages(
        pool=g.db_pool,
        channel_id=channel_id,
        user_hash=user_hash,
        limit=history_limit
    )

    logger.debug(f"[HISTORY_FETCHED] {len(history)}ê°œ ì¡°íšŒë¨")
    if len(history) < min_required:
        return f"ğŸ“‰ ë¶„ì„ì„ ìœ„í•œ ìµœì†Œ ëŒ€í™” ìˆ˜ëŠ” {min_required}ê°œì…ë‹ˆë‹¤. í˜„ì¬ëŠ” {len(history)}ê°œë°–ì— ì—†ì–´ìš”."

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    messages_text = "\n".join([f"- {msg}" for msg in history])
    system_prompt = (
        f"ë‹¤ìŒì€ '{sender}'ë‹˜ì˜ ê³¼ê±° ëŒ€í™” ê¸°ë¡ì…ë‹ˆë‹¤. ì´ ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì„±ê²©ê³¼ ì„±í–¥ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”.\n"
        f"ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ ì£¼ì„¸ìš”:\n"
        f"1. ì „ë°˜ì ì¸ ì„±ê²© íŠ¹ì„±(ì™¸í–¥/ë‚´í–¥, ê¸ì •/ë¶€ì • ë“±)\n"
        f"2. ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼ê³¼ ê´€ì‹¬ì‚¬\n"
        f"3. ëŒ€í™”ì—ì„œ ë“œëŸ¬ë‚˜ëŠ” ê°€ì¹˜ê´€ì´ë‚˜ ìš°ì„ ìˆœìœ„\n\n"
        f"ì§ì ‘ì ì´ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”. ë„ˆë¬´ ì§„ì§€í•˜ê±°ë‚˜ í•™ìˆ ì ì¸ ë¶„ì„ì€ í”¼í•´ì£¼ì„¸ìš”.\n\n"
        f"[ëŒ€í™” ê¸°ë¡]\n{messages_text}"
    )

    logger.debug("[PROFILE_ANALYSIS] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì™„ë£Œ")

    # ğŸ”¥ model íŒŒë¼ë¯¸í„°ë¡œ provider ì„¤ì •
    model_from_user = parameters.get("model")
    if model_from_user:
        provider_name = find_provider_by_model(model_from_user)
        if provider_name:
            providers = [{
                "name": provider_name,
                "model": model_from_user,
                "timeout": 30,
                "retry": 0,
                "system_prompt": system_prompt
            }]
            logger.debug(f"[PROFILE_ANALYSIS] ì‚¬ìš©ì ëª¨ë¸ ì ìš© â†’ {providers}")
        else:
            logger.warning(f"[PROFILE_ANALYSIS] ëª¨ë¸ '{model_from_user}'ì— ëŒ€í•œ providerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ providers ì‚¬ìš©")
            providers = get_default_providers(system_prompt)
    else:
        providers = get_default_providers(system_prompt)

    # ê°€ìƒì˜ received_message ê°ì²´ ìƒì„±
    received_message = {
        "bot_name": bot_name,
        "channel_id": channel_id,
        "user_hash": user_hash,
        "sender": sender,
        "room": room_name,
    }

    user_prompt = f"'{sender}'ë‹˜ì˜ ì„±ê²©ê³¼ ì„±í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”."
    result = await call_llm_with_fallback(received_message, user_prompt, providers)

    if not result:
        return "ì„±ê²© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

    final_result = f"ğŸ” {sender}ë‹˜ì˜ ì„±ê²© ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤!\n\n{result}"
    return final_result
